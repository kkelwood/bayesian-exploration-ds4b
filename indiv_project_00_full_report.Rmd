---
title: 'How does snowpack, Nitrogen, and temperature affect the phenology of an alpine grass?'
author: "Kelsey Elwood"
date: "12/21/2018"
output:     
    github_document:
        pandoc_args: --webtex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

This script is the final, summary report of a Bayesian hierarchical analysis of flowering time of Deschampsia cespitosa as a function of snow, nitrogen, and temperature. More information can be found on each part of the analysis by referring to the associated scripts available on github.

The following libraries are required for this script
```{r load-libraries, message = FALSE}
library(dplyr)
library(tidyr)
library(lme4)
library(ggplot2)
library(rstanarm)
library(rstan)
library(forcats)
options(mc.cores = parallel::detectCores())
theme_set(theme_grey()) #rstanarm overrides default ggplot theme: set it back

source("source/hpdi.R")
```

# 1. Introduction
The purpose of this analysis is to evaluate whether first flowering date (FFD) changes in response to increases in temperature, snowpack, and/or N. Data was collected for 2007 and 2008, though I only looked at 2007 data. The data are grouped at 2 levels: block and sub-block. There are a total of 3 blocks, each with 2 sub-blocks. Sub-blocks are separated by a snowfence with plots on the leeward side experiencing normal to reduced snowpack, while plots on the windward side experiencing increased snowpack. In each sub-block, 2 plots have warming treatments, 2 plots have increased nitrogen, 2 plots have both warming and increased nitrogen, and 2 plots are left as controls (ambient N and ambient temperature). Figure 1 (below) captures the conceptual layout of the data structure.

![Figure 1](figures/indiv-proj-method-schematic_kelsey-e.png)
*__Figure 1.__ The experimental design shows all 48 plots divided into blocks and sub-blocks. Each plot within a sub-block is 1 meter apart. The blocks are approximately 50 meters apart.*



# 2. Exploring the data 
_For more, see "indiv_project_2_eda.md"_

Load and clean the data
```{r data}
# Load data
nwt_ffd <- read.csv(file = "data/NWT_ITEX_FFD_data_2007_and_2008.csv", na.strings = ".") %>% 
    
    # create 0,1 vector for values
    mutate(Snow_x = ifelse(Snow == "X", "0", "1")) %>%
    mutate(Temp_x = ifelse(Temp == "X", "0", "1")) %>%
    mutate(N_x = ifelse(N == "X", "0", "1")) %>%   
    
    # rename the values to be more true to their meaning:
    mutate(Snow = as.factor(ifelse(Snow == "X", "Reduced_Snowpack", "Increased_Snowpack"))) %>%
    mutate(Temp = as.factor(ifelse(Temp == "X", "Normal_Temp", "Higher_Temp"))) %>%
    mutate(N = as.factor(ifelse(N == "X", "Ambient_N", "Increased_N"))) %>% 
    
    # create a new column for "subblock"
    mutate(Subblock = as.factor(ifelse(Snow == "Reduced_Snowpack", 0, 1))) %>% 
    
    # define "Block" as a factor
    mutate(Block = as.factor(Block)) %>% 
    
    # create a new Block|Subblock column
    mutate(Subblock_ID = as.factor(paste0(Block, "_", Subblock))) %>% 
    
    # remove 2 unnecessary (and empty) columns
    select(-c("X", "X.1")) 

# Convert data frame with species as a vector
nwt_ffd2 <- nwt_ffd %>% 
    gather(key = Species, value = FFD, 8:35, na.rm = TRUE, factor_key = TRUE) %>% 
    mutate(Species = factor(Species)) %>% 
    mutate(log_FFD = log(FFD)) 

# Subset data for 2007 (2008 was incomplete) and centered FFD
nwt_ffd2_2007 <- nwt_ffd2 %>% 
    filter(year == "2007") %>% 
    mutate(FFD_s = scale(FFD))

# create a new column for FFD based on visit number (rather than Julian day)
days_visited <- as.vector(sort(unique(nwt_ffd2_2007$FFD)))
number_visits <- length(days_visited)
Visit <- as.vector(1:number_visits)
visits_df <- data.frame(days_visited, Visit)
nwt_ffd2_2007 <- merge(nwt_ffd2_2007, visits_df, by.x = "FFD", by.y = "days_visited")

# subset of DESCAE (Deschampsia cespitosa) in 2007, with centered FFD
nwt_descae_2007 <- nwt_ffd2 %>% 
    filter(Species == "DESCAE") %>% 
    filter(year == "2007") %>% 
    merge(visits_df, by.x = "FFD", by.y = "days_visited") %>% 
    mutate(FFD_s = scale(FFD))

```

Explore data
```{r}
str(nwt_ffd2_2007)
```

```{r}
p2 <- ggplot(data = nwt_ffd2_2007) +
    geom_histogram(mapping = aes(x = Visit, y = stat(density), fill = Snow), position = "identity", alpha = 0.5, na.rm = TRUE, binwidth = 3) + 
    geom_density(mapping = aes(x = Visit, col = Snow)) +
    facet_grid(N ~ Temp) +
    labs(title = "Figure 2.", 
         subtitle = "FFD as a function of Snowpack, Temperature, and Nitrogen",
         x = "FFD (visit number) across all species")

p2
```
*__Figure 2.__ A histogram of all species as a function of snowpack, temperature, and nitrogen.*


Not all species are equally represented in the dataset:
```{r counts-of-observations-by-species}
species_list <- unique(nwt_ffd2$Species)
number_obs_df <- data.frame(ncol = 2, nrow = length(species_list))
colnames(number_obs_df) <- c("Species", "NA_count")

number_obs_df <- nwt_ffd2 %>% 
    group_by(Species, year) %>% 
    summarise(number_obs = n()) %>% 
    mutate(number_nas = 48 - number_obs) %>% 
    arrange(year, -number_obs)
head(number_obs_df)
```

One species, Deschampsia cespitosa (DESCAE), is present in all the plots in the 2007 data. For simplication, let's just use Deschampsia cespitosa for the hierarchical analysis.
```{r histogram-all-plots, warning=FALSE}
p3 <- ggplot() +
    geom_histogram(data = nwt_descae_2007, 
                   mapping = aes(x = Visit, y = stat(density)), 
                   binwidth = 1) + 
    geom_density(data = nwt_descae_2007, 
                 mapping = aes(x = Visit), 
                 col = "darkblue") +
    labs(title = "Figure 3.",
         subtitle = "FFD of Deschampsia cespitosa",
         x = "FFD (visit number) of Deschampsia cespitosa")
p3
```
*__Figure 3.__ A histogram of FFD of Deschampsia cespitosa across all plots.*

```{r}
p4 <- ggplot(data = nwt_descae_2007) +
    geom_histogram(mapping = aes(x = Visit, y = stat(density), fill = Snow,), position = "identity", alpha = 0.5, na.rm = TRUE, binwidth = 3) + 
    geom_density(mapping = aes(x = Visit, col = Snow)) +
    facet_grid(N ~ Temp) +
    labs(title = "Figure 4.", 
         subtitle = "FFD as a function of Snowpack, Temperature, and Nitrogen",
         x = "FFD (visit number) of Deschampsia cespitosa")

p4

```
*__Figure 4.__ A density histogram of FFD as a function of Snowpack, Temperature, and Nitrogen with a density smoother overlaid.*


```{r}
p5 <- ggplot(data = nwt_descae_2007) +
    geom_histogram(mapping = aes(x = Visit, y = stat(density), fill = Code), position = "identity", alpha = 0.5, na.rm = TRUE, binwidth = 4, stat = "density") + 
    labs(title = "Figure 5", 
         subtitle = "FFD of all 8 types of plots",
         x = "FFD of Deschampsia cespitosa")

p5

```
*__Figure 5__ A density plot of FFD for Deschampsia cespitosa in each of the 8 different types of plots (combinations of snow, nitrogen, and temperature).*

```{r warning = FALSE}
p6 <- ggplot(data = nwt_descae_2007, aes(x = Code, y = Visit, fill = Code, col = Code)) +
  stat_summary(geom = "point", fun.y = mean, position = "dodge") +
  stat_summary(geom = "errorbar", fun.data = mean_se, position = "dodge") + 
    labs(title = "Figure 6",
         subtitle = "First flowering data of each plot type",
         x = "Plot code",
         y = "First flowering date (visit) of Geum rossii")
p6
```
*__Figure 6.__ Mean and SE of FFD for Deschampsia cespitosa for all plot types.*

# 3. Define conceptual (biological) model

The purpose of the model is to evaluate how snowpack, temperature, and nitrogen impact the phenology of alpine plants. As discussed above, I will only look at one species (Deschampsia cespitosa) in one year (2007) for the sake of simplicity.

The structure of the experimental design has __2 grouping variables__: blocks (3 replicates separated in space) and 2 sub-blocks per block (separated by a snowfence). 

There are __3 explanatory variables__: snowpack (`Snow`), temperature (`Temp`), and nitrogen (`N`). 

The __response variable__ is the first flowering date of Deschampsia cespitosa, which is indicated by the visit number (`Visit`).

The following conceptual model considers all three explanatory variables and their interactions. I predicted that interactions might be important. I will evaluate this assumption when I build and compare models later in the script.

*__Plot level:__*        
$y_i \sim Normal(\mu_i, \sigma_y^2)$    
    $\mu_i = \alpha_{j[i]} + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2$    
    where...    
    - $y_i$ represents the observed value of FFD for a given plot $i$    
    - $\mu_i$ represents the expected FFD for plot $i$    
    - $\alpha_{j[i]}$ represents the expected value for a plot $i$ given it is within sub-block $j$     
    - $x_1$ represents N (2 levels: increased and ambient) and    
    - $x_2$ represents temperature (2 levels: increased and ambient)    
    - $x_3$ represents snow (2 levels: increased or decreased)    
           
*__Subblock level:__*        
$\alpha_{j} \sim Normal(\gamma_{k[i]}, \sigma_\mu^2)$    
    $\gamma_k = \omega_{k[i]} + \beta_4 x_3 + \beta_5 x_1 x_3 + \beta_6 x_2 x_3 + \beta_7 x_1 x_2 x_3$    
    where....    
    - $x_1$ represents N (2 levels: increased and ambient),        
    - $x_2$ represents temperature (2 levels: increased and ambient)     

*__Block level:__*\
$\omega_{k} \sim Normal(\bar{\omega}, \sigma_\omega^2)$    
    where...    
    - $\omega_{k}$ represents the mean among sub-blocks in blocks,        
    - $\bar{\omega}$ represents the mean among blocks, and     
    - $\sigma_\omega^2$ represents the variance among blocks

__Alternative Parameterization:__     
$y_i = x_1 * x_2 * x_3 + b_k + s_j + e_i$

*which expands to...*         
$y_i = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 + \beta_4 x_3 + \beta_5 x_1 x_3 + \beta_6 x_2 x_3 + \beta_7 x_1 x_2 x_3 + b_k + s_j + e_i$    
    where...   
    - $x_1$ represents N (2 levels: increased and ambient),        
    - $x_2$ represents temperature (2 levels: increased and ambient),      
    - $x_3$ represents snow (2 levels: increased or decreased),     
    - $b_k$ represents variance of a specific block $k$ from the mean of all blocks such that $b_k \sim Normal(0, \sigma_\omega^2)$,            
    - $s_j$ represents variance of a specific sub-block $j$ from the mean of sub-blocks such that $s_j \sim Normal(0, \sigma_\mu^2)$, and       
    - $e_i$ represents variance of a specific plot $i$ from the mean of plots such that  $e_i \sim Normal(\sigma_y^2)$ 
    
# Build and run Bayesian hierarchical models

_A selection of models are presented here for comparison. The following models were chosen based on a much more thorough model selection comparison in "indiv_project_5_model_selection"._

To start, let's look at the proposed conceptual model, which includes snow, temperature, nitrogen, and all their interactions as explanatory variables. I will use a normal, "gaussian" distribution for now, but I will return to this assumption later. Let's call this __"Model 1"__.

__Model 1: N x Temp x Snow__
```{r}
# Model 1: Visit, gaussian
bayes_NxTxS <- stan_glmer(Visit ~ N*Temp*Snow + (1|Block / Subblock), 
                          family = gaussian,
                          data = nwt_descae_2007,
                          adapt_delta = 0.999999)

```

I used default priors for the model, which mean that all parameters (including the intercept) have a default prior mean of 0, with variance of 10 for the intercept and 2.5 for the other parameters (default for normal distributions). The default priors are appropriate for this model because they are of the appropriate magnitude for the data, are weakly informative, and I don't have a good reason to use any other prior. 
```{r model1_priors}
prior_summary(bayes_NxTxS)
```

The covariance plot looks good. Values are below +/- 0.7:
```{r results = "hide"}
vcov(bayes_NxTxS, correlation=TRUE)
```


The diagnostics look fine too:
```{r eval = FALSE}
launch_shinystan(bayes_NxTxS)

```


```{r}
plot(bayes_NxTxS)
```
*__Figure 7.__ Looking at the posterior distribution, it appears that only nitrogen and temperature had a non-zero slope. Increased nitrogen or increased temperature appear to cause earlier flowering in Deschampsia cespitosa. The interaction between N and temperature is on the cusp, but interestingly, shows that the combination of increased N and increased temperature can delay flowering.*


Based on the results of the conceptual model, it appears that only N and temperature (and maybe their interaction) affect the flowering time of Deschampsia cespitosa. To explore this, here is __"Model 2"__, which only includes N, temperature, and N:temperature.

__Model 2: N x Temp__
```{r}
# Model 2: Visit, gaussian
bayes_NxT <- stan_glmer(Visit ~ N*Temp + (1|Block / Subblock), 
                          family = gaussian,
                          data = nwt_descae_2007,
                          adapt_delta = 0.999999)

```

I chose to use default priors because they are weakly informative and I don't have a good reason to use any other prior.
```{r model2_priors}
prior_summary(bayes_NxT)
```

The covariance plot looks good. Values are below +/- 0.7:
```{r results = "hide"}
vcov(bayes_NxT, correlation=TRUE)
```


The diagnostics look fine too:
```{r eval = FALSE}
launch_shinystan(bayes_NxT)

```

```{r}
plot(bayes_NxT)
```
*__Figure 8.__ The posterior distribution for model 2 looks similar to model 1, with only nitrogen and temperature having a non-zero slope. The interaction between N and temperature is still on the cusp.*

For exploration sake, let's build __"model 3", which excludes the interaction term.

__Model 3: N + Temp __
```{r}
# Model 1: Visit, gaussian
bayes_NT <- stan_glmer(Visit ~ N + Temp + (1|Block / Subblock), 
                          family = gaussian,
                          data = nwt_descae_2007,
                          adapt_delta = 0.99999999)

```

I chose to use default priors because they are weakly informative and I don't have a good reason to use any other prior.
```{r model3_priors}
prior_summary(bayes_NT)
```

The covariance plot looks good. Values are below +/- 0.4:
```{r results = "hide"}
vcov(bayes_NT, correlation=TRUE)
```


The diagnostics look fine too:
```{r eval = FALSE}
launch_shinystan(bayes_NT)

```


```{r}
plot(bayes_NT)
```
*__Figure 9.__ The results of the posterior distribution for model 3 match the results from model 1 and model 2. The posterior shows that increased N or increased temperature lead to earlier flowering.*

To compare the models, I used LOOIC. The LOOIC values for each model are reported below and show that the model with nitrogen, temperature, and nitrogen:temperature is likely the preferred model. The SE for the LOOIC values is relatively large, however, so all three models could be used. Fewer parameters is better, so either model 2 (N x temperature) or model 3 (N + temperature) are good contenders. I chose to explore model 2 (N x temperature) for the rest of the analysis because (1) it has the lowest LOOIC and (2) the interaction term has the opposite effect than each of the individual terms (the interaction delays flowering, while the individual terms cause earlier flowering), which could be biologically important.
```{r}
loo_NxTxS <- loo(bayes_NxTxS, k_threshold = 0.7)
loo_NxT <- loo(bayes_NxT, k_threshold = 0.7)
loo_NT <- loo(bayes_NT, k_threshold = 0.7)
compare_models(loo_NxTxS, loo_NxT, loo_NT)
```

# Simulate data to test model

Before continuing exploration of the model, I want to test the model algorithm using simulated data on a null model.

Define parameters
```{r define-parameters}
# Parameters for block level
meanblock <- 5.32 # also omega_bar (since data is centered, the value should be 0: 0 = average, negative = early, and positive = late flowering)
vblock <- 0.72 # variation between block 1, 2, 3: close to 1 day
nblock <- 3

#simulate block level
block_sim <- rnorm(nblock, meanblock, sqrt(vblock)) # the output would be the omega_k (see equation 5)

# parameters for subblock level
vsub <- 1.37 # bigger than between block variance (snow might be different?)
nsub <- 2 # 2 for each block


# simulate subblock level
blockmean_vector <- rep(block_sim, each = nsub) # repeat simulated mean of each block 2x (since there are 2 subblocks in each block); the length of the vector will be 6 (3 blocks x 2 subblocks/block)
subblock_sim <- rnorm(nsub*nblock, blockmean_vector, sqrt(vsub))

# parameters for data level
vy <- 2.32 # variance in FFD
n <- 32 # number of data points within a sub-block (32 = 4x as many as reality)

# Simulate data level (vectorized)    
subblockmean_vector <- rep(subblock_sim, each = n) # repeat simulated mean of each subblock n times each (length = 6 subblocks * n data/subblock)
y <- rnorm(n*nsub*nblock, subblockmean_vector, sqrt(vy)) #Simulate y depending on group means


# Compile into a dataframe
dat <- data.frame(Visit = y,
                  Block = factor(rep(1:nblock, each = nsub)),
                  Subblock = factor(rep(1:nsub, each = n)))
dat <- dat[order(dat$Block, dat$Subblock),]
head(dat)


# Add a random factor for species
dat2 <- data.frame(Visit = y,
                  Block = factor(rep(1:nblock, each = nsub)),
                  Subblock = factor(rep(1:nsub, each = n)),
                  Species = sample(1:20, n*nsub*nblock, replace = TRUE))
head(dat2)
```

Null model
```{r fit_model_null}
# Null model (no explanatory variables)
bayes_null_sim <- stan_glmer(Visit ~ 1 + (1 | Block / Subblock), 
                      data = dat,
                      family = gaussian,
                      adapt_delta = 0.99999)
summary(bayes_null_sim)[,c(1,3,10,9)] #a sample of the full output

# Explore the number of columns here so that I can adjust ncol in keep dataframe (when setting up simulation loop)

results <- c(fixef(bayes_null_sim), as.data.frame(VarCorr(bayes_null_sim))[,4])

loo_bayes_null_sim <- loo(bayes_null_sim)
```

# Repeat simulation numerous times (5000 or so is best, but I'll do 10)

```{r simulation-repeat, eval = FALSE}
# Setup
reps <- 10 #Number of replicate simulations
keep <- matrix(NA, nrow = reps, ncol = 8) # it was 6, but I think it will be 8 for my data

# Useful to add a timer. You could set reps to say 10 at first, then calculate
# how long it will take to run a larger simulation.
system.time(
for ( i in 1:reps ) {

#   Simulate block level
    block_sim <- rnorm(nblock, meanblock, sqrt(vblock))
    
#   simulate subblock level
    blockmean_vector <- rep(block_sim, each = nsub) # repeat simulated mean of each block 2x (since there are 2 subblocks in each block); the length of the vector will be 6 (3 blocks x 2 subblocks/block)
    subblock_sim <- rnorm(nsub*nblock, blockmean_vector, sqrt(vsub))

#   Simulate data level (vectorized)    
    subblockmean_vector <- rep(subblock_sim, each = n) # repeat simulated mean of each subblock n times each (length = 6 subblocks * n data/subblock)
    y <- rnorm(n*nsub*nblock, subblockmean_vector, sqrt(vy)) #Simulate y depending on group means

#   Fit model to simulated data
    dat <- data.frame(Visit = y,
                      Block = factor(rep(1:nblock, each = nsub)),
                      Subblock = factor(rep(1:nsub, each = n)))
    mlfit <- lmer(Visit ~ 1 + (1|Block/Subblock), 
                  data = dat, 
                  REML = FALSE)
    baysfit <- stan_lmer(Visit ~ 1 + (1|Block/Subblock), 
                         data = dat,
                         adapt_delta = 0.9999999999999999,
                         chains = 3)

#   Record results (VarCorr extracts the variance estimates)
    keep[i,] <- c(fixef(mlfit), as.data.frame(VarCorr(mlfit))[,4],
                  fixef(baysfit), as.data.frame(VarCorr(baysfit))[,4] )
    
#   Tidy up
    rm(block_sim, blockmean_vector, subblock_sim, subblockmean_vector, y, dat, mlfit, baysfit)
    
#   Monitoring progress   
    if ( i %% 10 == 0 ) {
        print(i) 
    }
}
)
save(keep, file="indiv_project_simulation_kelsey-e.RData") #Save the simulation for future use
```

The model had trouble converging on 3 of the 10 simulation, despite an adapt_delta very close to 1 and reducing the number of chains to 3. This may be an indication of a bigger problem with the model structure.

```{r load-data-file}
load(file="indiv_project_simulation_kelsey-e.RData")
head(keep)
```

```{r}

# Expected values of the algorith
ml_blockmean <- mean(keep[,1])
ml_vblock <- mean(keep[,2])
ml_vsub <- mean(keep[,3])
ml_vy <- mean(keep[,4])
b_blockmean <- mean(keep[,5])
b_vblock <- mean(keep[,6])
b_vsub <- mean(keep[,7])
b_vy <- mean(keep[,8])

```

Compare to the true values (as determined in defining the simulation data)
```{r}
# block-level mean
cbind(meanblock,ml_blockmean,b_blockmean)

# block-level variance
cbind(vblock,ml_vblock,b_vblock)

# sub-block level variance
cbind(vsub,ml_vsub,b_vsub)

# data-level variance
cbind(vy,ml_vy,b_vy)
```

Uh oh! The model did not do a good job recovering the values. The block-level means were pretty close, but the model did not have comparable values for the variance at the block, sub-block, or data-levels. The poor recovery of our initial values may suggest that the data would be better fit to another model structure. After discussions with Brett, the data structure might do better with a binomial, "event-based" approach (see "binomial_test.R" that Brett posted in my github repository). I will explore alternative models in the future, but for the remainder of this script, I will continue to use the normally distributed model.


# Summary of Bayesian Model

```{r}
summary(bayes_NxT)[,c(1,3,10,9)] #a sample of the full output

```
Note that the Rhat values are all close to, but not quite 1. The number of effective replicates, which would ideally be 4000, is not always that high.

```{r}
posterior_interval(bayes_NxT,prob=0.95)
```

```{r}
par(mfrow = c(1,1))
bayes_NxT$stanfit
traceplot(bayes_NxT$stanfit, pars = c("(Intercept)", "NIncreased_N", "TempNormal_Temp", "sigma", "Sigma[Subblock:Block:(Intercept),(Intercept)]", "Sigma[Block:(Intercept),(Intercept)]", "mean_PPD"))
```
*__Figure 10.__ A traceplot of the intercept of Model 2 shows that, although the model converged, there was a lot of variability through the end of the iterations.*


Sample from posterior (real data)
```{r}
#' Extract posterior samples:
samples <- extract(bayes_NxT$stanfit)
samplesdf <- data.frame(samples$alpha, samples$beta)
names(samplesdf) <- c("alpha", paste(names(samples[2]),1:3,sep="_"))
```

```{r}
samplesdf %>% 
  gather(key = "parameter", value = "sample") %>%
  ggplot() +
  geom_histogram(mapping = aes(x=sample, y=stat(density),fill=parameter),
                 bins=75, color="gray",lwd=1) +
  geom_vline(xintercept = 0, color = "blue") + 
  facet_wrap(facets = ~ parameter,scales="free")
```

```{r}
# Intercept
hpdi(samples$alpha[,1], prob=0.89)

# Nitrogen (Increased N)
hpdi(samples$beta[1,1], prob=0.89)

# Temperature (Warmer Temp)
hpdi(samples$beta[,2], prob=0.89)

# Nitrogen:Temperature (Increased N, Warmer Temp)
hpdi(samples$beta[,3], prob=0.89)
```

```{r}
pred <- predictive_interval(bayes_NxT,prob=0.95)
colnames(pred) <- c("pred_l","pred_u")
nwt_descae_2007 <- cbind(nwt_descae_2007, pred)

```

```{r}
p11 <- ggplot(data = nwt_descae_2007, aes(x = Code, fill = Temp, col = Temp, pch = N)) +
    geom_point(aes(y = jitter(Visit)), alpha = 0.8) +
    geom_linerange(aes(y = Visit), ymin = nwt_descae_2007$pred_l, ymax = nwt_descae_2007$pred_u) +
    labs(title = "Figure 11",
         subtitle = "Observed data and predicted data from Bayesian model",
         x = "Plot code",
         y = "First flowering date (visit number) of Deschampsia cespitosa") + 
    ylim(5, 10)
p11
```
*__Figure 11.__ The observed data (plotted as points) is overlaid with the predicted data from the model (lines). Overall, plots with higher temperatures flowered earlier than plots with normal temperatures. Plots with increased nitrogen, flowered earlier than plots with ambient nitrogen. Plots with both increased temperature and increased nitrogen flowered later.*

The preceding analysis showed that there may be some problematic assumptions with using a gaussian distribution for this data. Though the data is distributed relatively normally (see EDA), the number of total observations and the variance in the data are too small to effectively use a guassian GLMER. Future work should explore using a latent variable model, which was recommended by Brett Melbourne. 